{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fa3e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ZootrDataset \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_efficientnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m augmented_pred\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch_dataset'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.torch_dataset import ZootrDataset \n",
    "import os\n",
    "from pytorch_efficientnet import augmented_pred\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from src.preds_functions import choose_preds\n",
    "from skimage import io\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067e2f8",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a29c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FRAMES = r\"C:\\Users\\guilh\\Git\\ZOOTR\\Testes2\"\n",
    "PATH_TO_SAVE = r\"C:\\Users\\guilh\\Git\\ZOOTR\\Items grab preds\"\n",
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc05bbeb",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a78b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = torch.load('model.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071106d",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35224190",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = [os.path.join(PATH_TO_FRAMES, i) for i in os.listdir(PATH_TO_FRAMES) if i.endswith(\"png\")]\n",
    "\n",
    "test_set = ZootrDataset(test_imgs, False, augmented_pred)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=0, drop_last=False, shuffle=False)\n",
    "#Get test loader for video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9e7d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5721/5721 [50:33<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = torch.empty(0, 2)\n",
    "for imgs in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        imgs_pred = mdl(imgs)\n",
    "        all_preds = torch.cat((all_preds, imgs_pred))\n",
    "    gc.collect()\n",
    "#Get predictions dataframe for every saved frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f66f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\Git\\ZOOTR\\.venv_zootr\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "preds = torch.nn.Softmax()(all_preds)\n",
    "#Preds to probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf715caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_inds = choose_preds(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50d6e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for pred_img in range(len(items_inds)):\n",
    "    image = io.imread(test_imgs[items_inds[pred_img]])\n",
    "    #transforms.ToPILImage()(image).show() #check the image\n",
    "    prob = preds[items_inds][counter,1]\n",
    "    transforms.ToPILImage()(image).save(os.path.join(PATH_TO_SAVE, \"Pred_\" + \n",
    "                                                     str(counter) + \"_\" + \n",
    "                                                     str(prob.item())  + \n",
    "                                                     \"_\"  + \".png\"))\n",
    "    counter += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_zootr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
