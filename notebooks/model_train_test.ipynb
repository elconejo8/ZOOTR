{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2298b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from src.pytorch_efficientnet import EfficientNetwork, augment, augmented_pred\n",
    "from src.train_test_functions import train_model\n",
    "import json\n",
    "import numpy as np\n",
    "from src.torch_dataset import ZootrDataset \n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import mlflow\n",
    "from src.mlflow_functions import start_mlflow\n",
    "from contextlib import nullcontext\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd724876",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2adbbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "NUM_WORKERS = 0\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 0.1\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec1bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/paths_dict.json') as handle:\n",
    "    paths_dict = json.loads(handle.read())\n",
    "\n",
    "ITEM_PATH = paths_dict['item_path']\n",
    "NON_ITEM_PATH = paths_dict['non_item_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87811a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_objects = False\n",
    "save_data_objects = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11814890",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a346be",
   "metadata": {},
   "source": [
    "## Set up data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b4e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if  load_data_objects:\n",
    "    torch.load('Models/train_data.pth')\n",
    "    torch.load('Models/valid_data.pth')\n",
    "else:\n",
    "    items_images = [ITEM_PATH + i for i in os.listdir(ITEM_PATH)]\n",
    "    #Get all items\n",
    "    non_items_images = [NON_ITEM_PATH + i for i in os.listdir(NON_ITEM_PATH)]\n",
    "    #Get non items\n",
    "    all_images = list(np.random.permutation(items_images + non_items_images))\n",
    "    #Combine all images' paths and shuffle\n",
    "    train_data = ZootrDataset(all_images[0:int(np.ceil(len(all_images)*0.8))], transform_=augment)\n",
    "    train_data_eval = ZootrDataset(all_images[0:int(np.ceil(len(all_images)*0.8))], transform_=augmented_pred)\n",
    "    valid_data = ZootrDataset(all_images[int(np.ceil(len(all_images)*0.8)):], transform_=augmented_pred)\n",
    "    # Data Objects\n",
    "    if save_data_objects:\n",
    "        torch.save(train_data, 'Models/train_data.pth')\n",
    "        torch.save(valid_data, 'Models/valid_data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e2211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'train': all_images[0:int(np.ceil(len(all_images)*0.7))], \n",
    "        'val': all_images[int(np.ceil(len(all_images)*0.7)):int(np.ceil(len(all_images)*0.8))], \n",
    "        'test': all_images[int(np.ceil(len(all_images)*0.8)):]}\n",
    "transformations = {'train': augment, 'val': augmented_pred, 'test': augmented_pred}\n",
    "dataset_sizes = {'train': int(np.ceil(len(all_images)*0.7)), 'val': int(np.ceil(len(all_images)*0.8)) - int(np.ceil(len(all_images)*0.7)), \n",
    "                 'test': len(all_images) - int(np.ceil(len(all_images)*0.8))}\n",
    "\n",
    "datasets = {x: ZootrDataset(data[x], transform_=transformations[x]) for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, drop_last=True, shuffle=False) for x in ['train', 'val', 'test']}\n",
    "\n",
    "dics = {\n",
    "    'dataloaders': dataloaders,\n",
    "    'dataset_sizes': dataset_sizes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2280f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2e8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNetwork(output_size=2, b1=False, b2=True)\n",
    "# Criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max',\n",
    "                                                       patience=1, factor=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e60b5",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c01442be",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mlflow('zootr_img_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7248c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_RUN = True\n",
    "NR_EPOCHS = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68031928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:57<00:00,  1.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3745762825671277 Val loss: 0.3089926093096894\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:52<00:00,  1.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.15182275157717895 Val loss: 0.14785870657738856\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:52<00:00,  1.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08685727321183014 Val loss: 0.0978011484955244\n",
      "Training complete in 3m 6s\n",
      "Best val loss: 0.086857\n",
      "ðŸƒ View run delicate-snail-498 at: http://localhost:5000/#/experiments/873592191447312121/runs/28997c1fcb5846088497214958a53687\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/873592191447312121\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() if SAVE_RUN else nullcontext() as run:\n",
    "\n",
    "  if SAVE_RUN:\n",
    "   train_objects = {\n",
    "        \"model\": model,\n",
    "        \"criterion\": criterion,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"scheduler\": scheduler\n",
    "        }\n",
    "   \n",
    "   with open('train_objects.pkl', 'wb') as f:\n",
    "      pickle.dump(train_objects, f)\n",
    "   \n",
    "   mlflow.log_artifact('train_objects.pkl')\n",
    "  #Save initial objects - not checkpoint with optimized parameters - to retrain from scratch with the entire data later \n",
    "\n",
    "  mdl, loss_dict_collection = train_model(model.to(device), criterion, optimizer, scheduler, dics, num_epochs=NR_EPOCHS)\n",
    "  test_loader = dics['dataloaders']['test']\n",
    "\n",
    "  all_preds = torch.empty(0, 2)\n",
    "  all_labels = []\n",
    "  for imgs, label in test_loader:\n",
    "      imgs_pred = mdl(imgs)\n",
    "\n",
    "      all_preds = torch.cat((all_preds, imgs_pred))\n",
    "      all_labels += label\n",
    "  labels = [i.item() for i in all_labels]\n",
    "\n",
    "  preds_prob = torch.softmax(all_preds, dim=1)\n",
    "  preds_prob = pd.DataFrame(preds_prob.detach().numpy())\n",
    "  preds_prob.columns = ['False', 'True']\n",
    "  preds_prob['Label'] = labels\n",
    "\n",
    "  test_loss = criterion(all_preds, torch.tensor(labels)).item()\n",
    "  test_roc = roc_auc_score(preds_prob['Label'], preds_prob['True'])\n",
    "\n",
    "  if SAVE_RUN:\n",
    "\n",
    "    mlflow.log_dict(loss_dict_collection, 'loss_dict_collection.json')\n",
    "    #torch.save(model, 'base_model.pt')\n",
    "    #mlflow.log_artifact('base_model.pt')\n",
    "\n",
    "\n",
    "    mlflow.log_metrics({\"test_loss\": test_loss, \"test_roc\": test_roc})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_zootr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
